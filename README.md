# Project Title - Self-Supervised Learning for Unmanned Ground Vehicle Using Multi-Modal Data

About Project - Self-Supervised Learning for Unmanned Ground Vehicles Using Multi-Modal Data Unmanned Ground Vehicles (UGVs) have garnered increasing attention due to their
ability to autonomously navigate dynamic, unstructured environments. A key component for this autonomy is **semantic segmentation**, which allows the vehicle to understand its
surroundings.
This project addresses the challenge of limited annotated data in off-road environments by introducing a self-supervised learning pipeline. Using **RGB** and **LiDAR depth**
data as input, we fine-tune the **DeepLabV3+** segmentation model to improve perception and generalization in low-label regimes.
Our work leverages the **RELLIS-3D** dataset, a benchmark for UGV research and demonstrates improved segmentation performance under label-scarce conditions.

# Dataset
